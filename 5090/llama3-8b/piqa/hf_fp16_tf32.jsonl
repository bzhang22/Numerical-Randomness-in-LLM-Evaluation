{"id": 0, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7461389899253845, "Sol2": 0.2538609802722931}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 1, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.541893720626831, "Sol2": 0.45810624957084656}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 2, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.8665847778320312, "Sol2": 0.13341520726680756}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 3, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5428633093833923, "Sol2": 0.45713672041893005}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 4, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6825737357139587, "Sol2": 0.31742626428604126}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 5, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5869964361190796, "Sol2": 0.4130035936832428}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 6, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5234203934669495, "Sol2": 0.4765796959400177}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 7, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6976089477539062, "Sol2": 0.3023911118507385}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 8, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.8925625681877136, "Sol2": 0.10743748396635056}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 9, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.5448014140129089, "Sol2": 0.45519861578941345}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 10, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5755879878997803, "Sol2": 0.42441198229789734}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 11, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6334102749824524, "Sol2": 0.36658975481987}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 12, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6187804341316223, "Sol2": 0.3812195658683777}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 13, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.672331690788269, "Sol2": 0.32766830921173096}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 14, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7563575506210327, "Sol2": 0.2436424344778061}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 15, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.863391637802124, "Sol2": 0.13660839200019836}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 16, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7409248948097229, "Sol2": 0.2590751051902771}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 17, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7233095169067383, "Sol2": 0.2766905426979065}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 18, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.35756751894950867, "Sol2": 0.642432451248169}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 19, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.562176525592804, "Sol2": 0.4378235340118408}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 20, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6774740219116211, "Sol2": 0.3225259780883789}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 21, "label": "Sol1", "prediction": "Sol2", "correct": false, "choice_probs": {"Sol1": 0.4843800961971283, "Sol2": 0.5156199336051941}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 22, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7302899360656738, "Sol2": 0.26971015334129333}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 23, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5755879878997803, "Sol2": 0.42441198229789734}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 24, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6113819479942322, "Sol2": 0.38861799240112305}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 25, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7264255881309509, "Sol2": 0.2735743820667267}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 26, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5698526501655579, "Sol2": 0.43014734983444214}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 27, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.590779185295105, "Sol2": 0.40922078490257263}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 28, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7620701193809509, "Sol2": 0.23792991042137146}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 29, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7490872144699097, "Sol2": 0.25091278553009033}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 30, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7786493301391602, "Sol2": 0.22135069966316223}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 31, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6584175229072571, "Sol2": 0.3415825068950653}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 32, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6513549089431763, "Sol2": 0.3486451804637909}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 33, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6757646203041077, "Sol2": 0.3242354094982147}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 34, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.729519784450531, "Sol2": 0.270480215549469}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 35, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7704647779464722, "Sol2": 0.22953520715236664}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 36, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5467381477355957, "Sol2": 0.4532618224620819}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 37, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5945512652397156, "Sol2": 0.4054487347602844}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 38, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7098243832588196, "Sol2": 0.2901756167411804}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 39, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.45132654905319214, "Sol2": 0.5486735105514526}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 40, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.596433162689209, "Sol2": 0.4035668671131134}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 41, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.4455295503139496, "Sol2": 0.5544704794883728}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 42, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.8294920325279236, "Sol2": 0.17050801217556}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 43, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7534666657447815, "Sol2": 0.2465333491563797}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 44, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6460136771202087, "Sol2": 0.35398629307746887}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 45, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6636689305305481, "Sol2": 0.3363310396671295}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 46, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6731916666030884, "Sol2": 0.32680830359458923}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 47, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7892336845397949, "Sol2": 0.21076631546020508}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 48, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.39981159567832947, "Sol2": 0.6001883149147034}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 49, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.8006919622421265, "Sol2": 0.19930799305438995}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 50, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7074047327041626, "Sol2": 0.2925952970981598}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 51, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.826151430606842, "Sol2": 0.17384852468967438}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 52, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6406359076499939, "Sol2": 0.3593641519546509}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 53, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6388352513313293, "Sol2": 0.36116471886634827}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 54, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.43206337094306946, "Sol2": 0.5679365992546082}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 55, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6477982401847839, "Sol2": 0.35220178961753845}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 56, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7527403235435486, "Sol2": 0.24725967645645142}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 57, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.49511730670928955, "Sol2": 0.5048826336860657}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 58, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7341195344924927, "Sol2": 0.2658804655075073}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 59, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.5273165106773376, "Sol2": 0.47268345952033997}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 60, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.837619960308075, "Sol2": 0.16238003969192505}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 61, "label": "Sol1", "prediction": "Sol2", "correct": false, "choice_probs": {"Sol1": 0.4474602937698364, "Sol2": 0.5525397062301636}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 62, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7461389899253845, "Sol2": 0.2538609802722931}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 63, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.42823341488838196, "Sol2": 0.5717666149139404}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 64, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6095241904258728, "Sol2": 0.3904758393764496}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 65, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6566582322120667, "Sol2": 0.34334173798561096}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 66, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5087881684303284, "Sol2": 0.491211861371994}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 67, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6619228720664978, "Sol2": 0.3380770981311798}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 68, "label": "Sol1", "prediction": "Sol2", "correct": false, "choice_probs": {"Sol1": 0.4980468451976776, "Sol2": 0.5019530653953552}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 69, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.740174412727356, "Sol2": 0.2598256766796112}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 70, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6150878667831421, "Sol2": 0.3849121630191803}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 71, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.740174412727356, "Sol2": 0.2598256766796112}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 72, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7130321860313416, "Sol2": 0.2869679033756256}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 73, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.8019358515739441, "Sol2": 0.1980641782283783}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 74, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.5467381477355957, "Sol2": 0.4532618224620819}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 75, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.804405927658081, "Sol2": 0.19559408724308014}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 76, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6575384140014648, "Sol2": 0.34246155619621277}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 77, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6513549089431763, "Sol2": 0.3486451804637909}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 78, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5428633093833923, "Sol2": 0.45713672041893005}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 79, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.2628418505191803, "Sol2": 0.7371581792831421}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 80, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7185943722724915, "Sol2": 0.28140559792518616}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 81, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.842863142490387, "Sol2": 0.15713685750961304}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 82, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6001883149147034, "Sol2": 0.39981159567832947}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 83, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6433292627334595, "Sol2": 0.35667070746421814}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 84, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.842863142490387, "Sol2": 0.15713685750961304}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 85, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.665410578250885, "Sol2": 0.3345894515514374}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 86, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6076632142066956, "Sol2": 0.3923368752002716}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 87, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6020615696907043, "Sol2": 0.39793840050697327}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 88, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5234203934669495, "Sol2": 0.4765796959400177}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 89, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.642432451248169, "Sol2": 0.35756751894950867}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 90, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7122321724891663, "Sol2": 0.28776779770851135}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 91, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5945512652397156, "Sol2": 0.4054487347602844}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 92, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6132365465164185, "Sol2": 0.38676345348358154}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 93, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6808785796165466, "Sol2": 0.3191213607788086}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 94, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5736784338951111, "Sol2": 0.4263215959072113}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 95, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6039317846298218, "Sol2": 0.39606812596321106}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 96, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.8418256044387817, "Sol2": 0.15817435085773468}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 97, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7826625108718872, "Sol2": 0.21733751893043518}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 98, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.581303060054779, "Sol2": 0.41869691014289856}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 99, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.8104788661003113, "Sol2": 0.18952107429504395}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
