{"id": 0, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.745987594127655, "Sol2": 0.25401240587234497}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 1, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5410890579223633, "Sol2": 0.4589109420776367}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 2, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.8675657510757446, "Sol2": 0.13243427872657776}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 3, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5431067943572998, "Sol2": 0.4568931758403778}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 4, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6831063032150269, "Sol2": 0.31689372658729553}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 5, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5853919982910156, "Sol2": 0.414607971906662}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 6, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5246853232383728, "Sol2": 0.4753146767616272}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 7, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6976218223571777, "Sol2": 0.30237820744514465}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 8, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.8926480412483215, "Sol2": 0.10735200345516205}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 9, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.5446962714195251, "Sol2": 0.45530372858047485}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 10, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5755728483200073, "Sol2": 0.4244270920753479}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 11, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6331449151039124, "Sol2": 0.36685508489608765}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 12, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6182518601417542, "Sol2": 0.38174816966056824}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 13, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6716329455375671, "Sol2": 0.3283670246601105}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 14, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7557327747344971, "Sol2": 0.24426721036434174}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 15, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.8635475635528564, "Sol2": 0.13645245134830475}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 16, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7408841848373413, "Sol2": 0.2591158449649811}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 17, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7228385806083679, "Sol2": 0.27716144919395447}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 18, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.35828444361686707, "Sol2": 0.6417155861854553}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 19, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5609531402587891, "Sol2": 0.43904680013656616}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 20, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6765710711479187, "Sol2": 0.3234289288520813}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 21, "label": "Sol1", "prediction": "Sol2", "correct": false, "choice_probs": {"Sol1": 0.483750581741333, "Sol2": 0.516249418258667}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 22, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7304323315620422, "Sol2": 0.26956766843795776}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 23, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.574744701385498, "Sol2": 0.42525535821914673}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 24, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6116187572479248, "Sol2": 0.38838130235671997}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 25, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7263103723526001, "Sol2": 0.2736896276473999}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 26, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5686104893684387, "Sol2": 0.43138957023620605}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 27, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.5897426605224609, "Sol2": 0.4102573096752167}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 28, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7623582482337952, "Sol2": 0.23764175176620483}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 29, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.748437762260437, "Sol2": 0.251562237739563}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 30, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7783915996551514, "Sol2": 0.22160835564136505}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 31, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6589690446853638, "Sol2": 0.34103095531463623}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 32, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6505362391471863, "Sol2": 0.3494637906551361}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 33, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6752476096153259, "Sol2": 0.3247523605823517}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 34, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7306658029556274, "Sol2": 0.26933425664901733}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 35, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7709671258926392, "Sol2": 0.22903282940387726}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 36, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.548926830291748, "Sol2": 0.4510730803012848}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 37, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5948707461357117, "Sol2": 0.40512919425964355}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 38, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7104305624961853, "Sol2": 0.2895694077014923}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 39, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.45156410336494446, "Sol2": 0.5484359264373779}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 40, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.5967503786087036, "Sol2": 0.40324968099594116}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 41, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.4461991786956787, "Sol2": 0.5538008213043213}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 42, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.8289574980735779, "Sol2": 0.1710425317287445}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 43, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7539166808128357, "Sol2": 0.2460833042860031}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 44, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6462973952293396, "Sol2": 0.3537026345729828}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 45, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6650310158729553, "Sol2": 0.3349689543247223}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 46, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6731529831886292, "Sol2": 0.32684704661369324}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 47, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7899096012115479, "Sol2": 0.21009033918380737}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 48, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.39910703897476196, "Sol2": 0.6008930206298828}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 49, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.8002486228942871, "Sol2": 0.19975130259990692}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 50, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7074944972991943, "Sol2": 0.2925054728984833}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 51, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.8261250853538513, "Sol2": 0.1738748997449875}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 52, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6409765481948853, "Sol2": 0.35902348160743713}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 53, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6385980248451233, "Sol2": 0.3614019453525543}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 54, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.43374136090278625, "Sol2": 0.5662586092948914}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 55, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6488532423973083, "Sol2": 0.35114678740501404}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 56, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7531546354293823, "Sol2": 0.24684534966945648}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 57, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.4948357939720154, "Sol2": 0.5051642060279846}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 58, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7335426211357117, "Sol2": 0.26645734906196594}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 59, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.5271703600883484, "Sol2": 0.472829669713974}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 60, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.838113009929657, "Sol2": 0.16188696026802063}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 61, "label": "Sol1", "prediction": "Sol2", "correct": false, "choice_probs": {"Sol1": 0.44672948122024536, "Sol2": 0.5532705187797546}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 62, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7460275292396545, "Sol2": 0.25397247076034546}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 63, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.42835691571235657, "Sol2": 0.571643054485321}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 64, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6088550686836243, "Sol2": 0.3911449611186981}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 65, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6559559106826782, "Sol2": 0.3440440595149994}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 66, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5092203617095947, "Sol2": 0.4907795786857605}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 67, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6631195545196533, "Sol2": 0.33688050508499146}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 68, "label": "Sol1", "prediction": "Sol2", "correct": false, "choice_probs": {"Sol1": 0.4988267421722412, "Sol2": 0.5011732578277588}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 69, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.7392180562019348, "Sol2": 0.2607819736003876}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 70, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6160440444946289, "Sol2": 0.3839559257030487}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 71, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7409620881080627, "Sol2": 0.25903797149658203}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 72, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7139063477516174, "Sol2": 0.28609365224838257}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 73, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.8020695447921753, "Sol2": 0.1979304552078247}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 74, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.5473336577415466, "Sol2": 0.45266634225845337}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 75, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.805337131023407, "Sol2": 0.1946629285812378}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 76, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6572285890579224, "Sol2": 0.34277141094207764}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 77, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6516889333724976, "Sol2": 0.34831103682518005}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 78, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5404634475708008, "Sol2": 0.45953652262687683}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 79, "label": "Sol2", "prediction": "Sol2", "correct": true, "choice_probs": {"Sol1": 0.2619791030883789, "Sol2": 0.7380208969116211}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 80, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7189508676528931, "Sol2": 0.2810491621494293}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 81, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.842269778251648, "Sol2": 0.15773014724254608}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 82, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5994070172309875, "Sol2": 0.4005929231643677}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 83, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.64347904920578, "Sol2": 0.3565209209918976}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 84, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.8423895835876465, "Sol2": 0.1576104760169983}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 85, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6673877835273743, "Sol2": 0.33261221647262573}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 86, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6064800024032593, "Sol2": 0.39351993799209595}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 87, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.601201057434082, "Sol2": 0.39879897236824036}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 88, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.521905243396759, "Sol2": 0.47809478640556335}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 89, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6412968635559082, "Sol2": 0.3587031066417694}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 90, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7124998569488525, "Sol2": 0.2875001132488251}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 91, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5959411263465881, "Sol2": 0.40405887365341187}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 92, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6140621900558472, "Sol2": 0.3859378695487976}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 93, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.6815537810325623, "Sol2": 0.31844624876976013}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 94, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.5740063190460205, "Sol2": 0.4259937107563019}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 95, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.6033506989479065, "Sol2": 0.3966493308544159}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 96, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.8416715860366821, "Sol2": 0.15832845866680145}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 97, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.7825986742973328, "Sol2": 0.21740126609802246}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 98, "label": "Sol1", "prediction": "Sol1", "correct": true, "choice_probs": {"Sol1": 0.5821923017501831, "Sol2": 0.4178076982498169}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
{"id": 99, "label": "Sol2", "prediction": "Sol1", "correct": false, "choice_probs": {"Sol1": 0.8109426498413086, "Sol2": 0.1890573799610138}, "dataset": "piqa", "backend": "hf", "model": "NousResearch/Meta-Llama-3-8B"}
